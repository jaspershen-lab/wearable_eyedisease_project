library(tidyverse)
library(rstanarm)
library(bayesplot)
library(ggplot2)
library(gridExtra)
library(r4projects)
library(pROC)
library(loo)

# è®¾ç½®è´å¶æ–¯åˆ†æé€‰é¡¹
options(mc.cores = parallel::detectCores())

# Set working directory
setwd(get_project_wd())
rm(list = ls())

# ================== 1. æ•°æ®å‡†å¤‡ ==================

cat("===== å¯ç©¿æˆ´è®¾å¤‡æŒ‡æ ‡é¢„æµ‹OCTAé¢„ååˆ†æ - åŒæ¨¡å‹ç­–ç•¥ =====\n")

# åŠ è½½æ•°æ®æ–‡ä»¶
raw_wearable_file <- "3_data_analysis/6_clustering_modeling/data_prepare/1m/mfuzz_D_Surg1_8h_filtered.csv"
wearable_cluster_file <- "3_data_analysis/6_clustering_modeling/time_window_clustering/late_recovery_detailed_membership_fixed.csv"
outcome_file <- "3_data_analysis/6_clustering_modeling/mfuzz/comprehensive_cluster/ppv_WF_cluster_results.csv"
baseline_info <- read.csv("2_data/analysis_data/baseline_info.csv", stringsAsFactors = FALSE)

# å®‰å…¨åŠ è½½æ•°æ®å‡½æ•°
load_data_safely <- function(file_path, data_name) {
  if(file.exists(file_path)) {
    data <- read.csv(file_path, stringsAsFactors = FALSE)
    cat(sprintf("âœ“ æˆåŠŸåŠ è½½ %s: %d è¡Œæ•°æ®\n", data_name, nrow(data)))
    return(data)
  } else {
    cat(sprintf("âŒ æ–‡ä»¶ä¸å­˜åœ¨: %s\n", file_path))
    stop(sprintf("å¿…éœ€çš„æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: %s", file_path))
  }
}

# åŠ è½½æ•°æ®
raw_wearable_data <- load_data_safely(raw_wearable_file, "åŸå§‹å¯ç©¿æˆ´è®¾å¤‡æ•°æ®")
wearable_cluster_data <- load_data_safely(wearable_cluster_file, "å¯ç©¿æˆ´è®¾å¤‡èšç±»ç»“æœ")
outcome_data <- load_data_safely(outcome_file, "OCTAé¢„åæ•°æ®")

# æå–Late Recoveryæ—¶é—´çª—å£çš„æŒ‡æ ‡å‡½æ•°
extract_late_recovery_metrics <- function(raw_data) {
  late_recovery_days <- 16:30
  
  cv_rhr_cols <- c()
  steps_max_cols <- c()
  
  for(day in late_recovery_days) {
    cv_rhr_col <- paste0("day_", day, "_cv_rhr_1")
    steps_max_col <- paste0("day_", day, "_steps_max")
    
    if(cv_rhr_col %in% colnames(raw_data)) {
      cv_rhr_cols <- c(cv_rhr_cols, cv_rhr_col)
    }
    if(steps_max_col %in% colnames(raw_data)) {
      steps_max_cols <- c(steps_max_cols, steps_max_col)
    }
  }
  
  cat("æ‰¾åˆ°çš„Late Recovery CV RHRåˆ—:", length(cv_rhr_cols), "ä¸ª\n")
  cat("æ‰¾åˆ°çš„Late Recovery Steps Maxåˆ—:", length(steps_max_cols), "ä¸ª\n")
  
  result_data <- data.frame(subject_id = raw_data$subject_id)
  
  # è®¡ç®—Late RecoveryæœŸé—´çš„å¹³å‡å€¼
  cv_rhr_data <- raw_data[, cv_rhr_cols, drop = FALSE]
  result_data$late_recovery_cv_rhr_1 <- rowMeans(cv_rhr_data, na.rm = TRUE)
  
  steps_max_data <- raw_data[, steps_max_cols, drop = FALSE]
  result_data$late_recovery_steps_max <- rowMeans(steps_max_data, na.rm = TRUE)
  
  return(result_data)
}

wearable_metrics <- extract_late_recovery_metrics(raw_wearable_data)

# è®¾ç½®è¾“å‡ºç›®å½•
output_dir <- "3_data_analysis/6_clustering_modeling/late_recovery_subanalysis/two_model_bayesian_analysis"
dir.create(output_dir, recursive = TRUE, showWarnings = FALSE)
setwd(output_dir)

# ç»Ÿä¸€IDåˆ—å
standardize_id_column <- function(data) {
  if("subject_id" %in% names(data)) {
    return(data)
  } else if("ID" %in% names(data)) {
    names(data)[names(data) == "ID"] <- "subject_id"
    return(data)
  } else {
    stop("æ‰¾ä¸åˆ°IDåˆ— (subject_id æˆ– ID)")
  }
}

wearable_metrics <- standardize_id_column(wearable_metrics)
wearable_cluster_data <- standardize_id_column(wearable_cluster_data)
outcome_data <- standardize_id_column(outcome_data)

# åˆå¹¶æ•°æ®
wearable_combined <- merge(wearable_metrics, wearable_cluster_data, 
                           by = "subject_id", suffixes = c("", "_cluster"))

prediction_data <- merge(wearable_combined, outcome_data, 
                         by = "subject_id", suffixes = c("_wearable", "_outcome"))

# åˆ›å»ºäºŒåˆ†ç±»ç›®æ ‡å˜é‡
prediction_data$good_outcome <- ifelse(prediction_data$max_cluster_outcome == 2, 1, 0)
prediction_data$outcome_label <- factor(prediction_data$good_outcome, 
                                        levels = c(0, 1), 
                                        labels = c("Poor Outcome", "Good Outcome"))

# åˆ›å»ºç‰¹å¾æ•°æ®æ¡†
features_data <- data.frame(
  subject_id = prediction_data$subject_id,
  cv_rhr = prediction_data$late_recovery_cv_rhr_1,
  steps_max = prediction_data$late_recovery_steps_max,
  wearable_cluster = prediction_data$max_cluster_wearable,
  outcome = prediction_data$outcome_label,
  good_outcome = prediction_data$good_outcome
)

# å¤„ç†ç¼ºå¤±å€¼
initial_n <- nrow(features_data)
features_data <- features_data[complete.cases(features_data[, c("cv_rhr", "steps_max", "good_outcome")]), ]
final_n <- nrow(features_data)

cat("æ ·æœ¬å¤„ç†:\n")
cat("- åˆå§‹æ ·æœ¬æ•°:", initial_n, "\n")
cat("- å®Œæ•´æ¡ˆä¾‹æ•°:", final_n, "\n")

# ================== 2. æ•´åˆä¸´åºŠå˜é‡ï¼ˆä»…å¹´é¾„å’Œæ€§åˆ«ï¼‰==================

cat("\n===== æ•´åˆä¸´åºŠå˜é‡ (å¹´é¾„ + æ€§åˆ«) =====\n")

# æ•´åˆä¸´åºŠåŸºçº¿ä¿¡æ¯
if(ncol(baseline_info) >= 2) {
  colnames(baseline_info)[2] <- "subject_id"
}

if("subject_id" %in% names(baseline_info)) {
  features_data <- features_data %>%
    left_join(baseline_info %>% dplyr::select(subject_id, age, gender), 
              by = "subject_id")
  
  # æ•°æ®æ¸…ç†å‡½æ•°ï¼šå¤„ç† "." ä½œä¸ºç¼ºå¤±å€¼çš„æƒ…å†µ
  clean_numeric_column <- function(x) {
    x[x == "." | x == "" | is.na(x)] <- NA
    as.numeric(x)
  }
  
  # æ¸…ç†ä¸´åºŠå˜é‡
  features_data <- features_data %>%
    mutate(
      age = clean_numeric_column(age),
      gender = clean_numeric_column(gender)
    )
  
  # æ£€æŸ¥ä¸´åºŠå˜é‡å®Œæ•´æ€§
  clinical_completeness <- features_data %>%
    summarise(
      age_complete = sum(!is.na(age)),
      gender_complete = sum(!is.na(gender)),
      total_n = n()
    )
  
  cat("ä¸´åºŠå˜é‡å®Œæ•´æ€§:\n")
  cat("- Age:", clinical_completeness$age_complete, "/", clinical_completeness$total_n, "\n")
  cat("- Gender:", clinical_completeness$gender_complete, "/", clinical_completeness$total_n, "\n")
  
  # å†³å®šæ˜¯å¦çº³å…¥ä¸´åºŠå˜é‡
  use_clinical <- (clinical_completeness$age_complete >= final_n * 0.7 && 
                     clinical_completeness$gender_complete >= final_n * 0.7)
  
  cat("åˆ†æç­–ç•¥:\n")
  cat("- ä½¿ç”¨ä¸´åºŠå˜é‡ (Age + Gender):", ifelse(use_clinical, "æ˜¯", "å¦"), "\n")
  cat("- æ’é™¤HbA1c: æ˜¯ (é¿å…å°æ ·æœ¬å¼‚å¸¸å…³è”)\n")
  
} else {
  use_clinical <- FALSE
  cat("âš ï¸ æœªæ‰¾åˆ°ä¸´åºŠåŸºçº¿ä¿¡æ¯ï¼Œä»…ä½¿ç”¨å¯ç©¿æˆ´è®¾å¤‡æ•°æ®\n")
}

# ================== 3. æ•°æ®æ ‡å‡†åŒ– ==================

cat("\n===== æ•°æ®æ ‡å‡†åŒ– =====\n")

# ä¸ºè´å¶æ–¯åˆ†ææ ‡å‡†åŒ–è¿ç»­å˜é‡
features_data_scaled <- features_data %>%
  mutate(
    cv_rhr_scaled = as.numeric(scale(cv_rhr)),
    steps_max_scaled = as.numeric(scale(steps_max))
  )

if(use_clinical) {
  features_data_scaled <- features_data_scaled %>%
    mutate(
      age_scaled = if(!all(is.na(age))) as.numeric(scale(age)) else NA_real_,
      gender = factor(gender, levels = c(0, 1), labels = c("Female", "Male"))
    )
}

cat("æ ‡å‡†åŒ–å®Œæˆ:\n")
cat("- CV RHRæ ‡å‡†åŒ–: å‡å€¼=0, æ ‡å‡†å·®=1\n")
cat("- Steps Maxæ ‡å‡†åŒ–: å‡å€¼=0, æ ‡å‡†å·®=1\n")
if(use_clinical) {
  cat("- Ageæ ‡å‡†åŒ–: å‡å€¼=0, æ ‡å‡†å·®=1\n")
  cat("- Genderå› å­åŒ–: Female/Male\n")
}

# ================== 4. åŒæ¨¡å‹è´å¶æ–¯é€»è¾‘å›å½’ ==================

cat("\n===== åŒæ¨¡å‹è´å¶æ–¯é€»è¾‘å›å½’åˆ†æ =====\n")

# è®¾ç½®å…ˆéªŒåˆ†å¸ƒ
prior_coef <- rstanarm::normal(0, 2.5)  # ç³»æ•°çš„å…ˆéªŒ
prior_intercept <- rstanarm::normal(0, 5)  # æˆªè·çš„å…ˆéªŒ

# MCMCè®¾ç½®
chains <- 4
iter <- 4000
warmup <- 2000
seed <- 2025

cat("è´å¶æ–¯è®¾ç½®:\n")
cat("- å…ˆéªŒåˆ†å¸ƒ: ç³»æ•° ~ N(0, 2.5), æˆªè· ~ N(0, 5)\n")
cat("- MCMCé“¾æ•°:", chains, "\n")
cat("- è¿­ä»£æ¬¡æ•°:", iter, "\n")
cat("- é¢„çƒ­æ¬¡æ•°:", warmup, "\n")

# æ¨¡å‹1: å¯ç©¿æˆ´è®¾å¤‡æ¨¡å‹ (ä¸»è¦åˆ†æ)
cat("\nè®­ç»ƒæ¨¡å‹1: å¯ç©¿æˆ´è®¾å¤‡æ¨¡å‹...\n")

model_wearable <- stan_glm(
  good_outcome ~ cv_rhr_scaled + steps_max_scaled,
  data = features_data_scaled,
  family = binomial(link = "logit"),
  prior = prior_coef,
  prior_intercept = prior_intercept,
  chains = chains,
  iter = iter,
  warmup = warmup,
  seed = seed,
  cores = 4,
  refresh = 0
)

cat("âœ“ å¯ç©¿æˆ´è®¾å¤‡æ¨¡å‹è®­ç»ƒå®Œæˆ\n")

# æ¨¡å‹2: è”åˆæ¨¡å‹ (æ•æ„Ÿæ€§åˆ†æ)
model_combined <- NULL

if(use_clinical) {
  # å‡†å¤‡è”åˆæ¨¡å‹æ•°æ®
  combined_data <- features_data_scaled %>%
    filter(!is.na(age_scaled), !is.na(gender), !is.na(cv_rhr_scaled), !is.na(steps_max_scaled))
  
  if(nrow(combined_data) >= 5) {
    cat("è®­ç»ƒæ¨¡å‹2: è”åˆæ¨¡å‹ (å¯ç©¿æˆ´è®¾å¤‡ + å¹´é¾„ + æ€§åˆ«)...\n")
    
    model_combined <- stan_glm(
      good_outcome ~ cv_rhr_scaled + steps_max_scaled + age_scaled + gender,
      data = combined_data,
      family = binomial(link = "logit"),
      prior = prior_coef,
      prior_intercept = prior_intercept,
      chains = chains,
      iter = iter,
      warmup = warmup,
      seed = seed,
      cores = 4,
      refresh = 0
    )
    
    cat("âœ“ è”åˆæ¨¡å‹è®­ç»ƒå®Œæˆ\n")
  } else {
    cat("âŒ è”åˆæ¨¡å‹æ•°æ®ä¸è¶³ï¼Œè·³è¿‡è”åˆæ¨¡å‹\n")
  }
} else {
  cat("âŒ ä¸´åºŠå˜é‡ä¸å¯ç”¨ï¼Œä»…åˆ†æå¯ç©¿æˆ´è®¾å¤‡æ¨¡å‹\n")
}

# åˆ›å»ºæ¨¡å‹åˆ—è¡¨
bayes_models <- list("Wearable Devices" = model_wearable)
if(!is.null(model_combined)) {
  bayes_models[["Combined Model"]] <- model_combined
}

cat("\næœ€ç»ˆåˆ†ææ¨¡å‹:\n")
for(i in seq_along(bayes_models)) {
  cat(sprintf("%d. %s\n", i, names(bayes_models)[i]))
}

# ================== 5. æ¨¡å‹è¯Šæ–­å’Œæ”¶æ•›æ€§æ£€æŸ¥ ==================

cat("\n===== æ¨¡å‹è¯Šæ–­å’Œæ”¶æ•›æ€§æ£€æŸ¥ =====\n")

# æ£€æŸ¥æ”¶æ•›æ€§
check_convergence <- function(model, model_name) {
  cat(sprintf("\n%s æ”¶æ•›æ€§è¯Šæ–­:\n", model_name))
  
  # Rhatç»Ÿè®¡é‡
  rhat_values <- rhat(model)
  max_rhat <- max(rhat_values, na.rm = TRUE)
  
  # æœ‰æ•ˆæ ·æœ¬é‡
  neff_values <- neff_ratio(model)
  min_neff <- min(neff_values, na.rm = TRUE)
  
  cat(sprintf("- æœ€å¤§Rhat: %.3f (åº”è¯¥ < 1.1)\n", max_rhat))
  cat(sprintf("- æœ€å°æœ‰æ•ˆæ ·æœ¬æ¯”ä¾‹: %.3f (åº”è¯¥ > 0.1)\n", min_neff))
  
  # åˆ¤æ–­æ”¶æ•›
  converged <- (max_rhat < 1.1) && (min_neff > 0.1)
  cat(sprintf("- æ”¶æ•›çŠ¶æ€: %s\n", ifelse(converged, "âœ“ æ”¶æ•›", "âŒ æœªæ”¶æ•›")))
  
  return(list(
    converged = converged,
    max_rhat = max_rhat,
    min_neff = min_neff
  ))
}

convergence_results <- list()
for(name in names(bayes_models)) {
  convergence_results[[name]] <- check_convergence(bayes_models[[name]], name)
}

# ================== 6. åéªŒåˆ†å¸ƒåˆ†æ ==================

cat("\n===== åéªŒåˆ†å¸ƒåˆ†æ =====\n")

# æå–åéªŒæ‘˜è¦
get_posterior_summary <- function(model, model_name) {
  cat(sprintf("\n%s åéªŒç»Ÿè®¡:\n", model_name))
  
  # æ‰“å°æ¨¡å‹æ‘˜è¦
  model_summary <- summary(model, digits = 3)
  print(model_summary)
  
  return(model_summary)
}

posterior_summaries <- list()
for(name in names(bayes_models)) {
  posterior_summaries[[name]] <- get_posterior_summary(bayes_models[[name]], name)
}

# ================== 7. è¯¦ç»†å¯ä¿¡åŒºé—´åˆ†æ ==================

cat("\n===== å¯ä¿¡åŒºé—´åˆ†æ =====\n")

# å¯ä¿¡åŒºé—´åˆ†æ
analyze_credible_intervals <- function(model, model_name) {
  cat(sprintf("\n%s å¯ä¿¡åŒºé—´åˆ†æ:\n", model_name))
  
  # æå–åéªŒæ ·æœ¬
  posterior <- as.matrix(model)
  param_names <- colnames(posterior)
  coef_params <- param_names[!param_names %in% c("(Intercept)", "sigma")]
  
  # è®¡ç®—ä¸åŒæ°´å¹³çš„å¯ä¿¡åŒºé—´
  ci_levels <- c(0.5, 0.8, 0.95)
  
  for(param in coef_params) {
    cat(sprintf("\nå‚æ•°: %s\n", param))
    
    posterior_samples <- posterior[, param]
    
    # åéªŒå‡å€¼å’Œæ ‡å‡†å·®
    post_mean <- mean(posterior_samples)
    post_sd <- sd(posterior_samples)
    
    cat(sprintf("  åéªŒå‡å€¼: %.3f (SD: %.3f)\n", post_mean, post_sd))
    
    # å¯ä¿¡åŒºé—´
    for(level in ci_levels) {
      alpha <- 1 - level
      ci <- quantile(posterior_samples, c(alpha/2, 1-alpha/2))
      
      # æ£€æŸ¥0æ˜¯å¦åœ¨å¯ä¿¡åŒºé—´å†…
      includes_zero <- ci[1] <= 0 && ci[2] >= 0
      significance <- ifelse(includes_zero, "", " *")
      
      cat(sprintf("  %d%% CI: [%.3f, %.3f]%s\n", 
                  level*100, ci[1], ci[2], significance))
    }
    
    # è®¡ç®—P(Î² > 0)çš„æ¦‚ç‡
    prob_positive <- mean(posterior_samples > 0)
    cat(sprintf("  P(Î² > 0): %.3f\n", prob_positive))
  }
}

# å¯¹æ‰€æœ‰æ¨¡å‹è¿›è¡Œå¯ä¿¡åŒºé—´åˆ†æ
for(name in names(bayes_models)) {
  analyze_credible_intervals(bayes_models[[name]], name)
}

# ================== 8. é¢„æµ‹æ€§èƒ½è¯„ä¼° ==================

cat("\n===== é¢„æµ‹æ€§èƒ½è¯„ä¼° =====\n")

# è¯„ä¼°è´å¶æ–¯æ¨¡å‹æ€§èƒ½
evaluate_bayesian_model <- function(model, data, model_name) {
  
  # è®¡ç®—é¢„æµ‹æ¦‚ç‡
  pred_probs <- posterior_epred(model)  # ä½¿ç”¨æ¨èçš„å‡½æ•°
  mean_pred_probs <- colMeans(pred_probs)
  
  # åˆ›å»ºROCæ›²çº¿
  actual_outcomes <- data$good_outcome
  
  if(length(unique(actual_outcomes)) == 2) {
    roc_obj <- roc(actual_outcomes, mean_pred_probs, quiet = TRUE)
    auc_value <- as.numeric(auc(roc_obj))
    
    # è®¡ç®—å…¶ä»–æŒ‡æ ‡
    pred_class <- ifelse(mean_pred_probs > 0.5, 1, 0)
    confusion_matrix <- table(Predicted = pred_class, Actual = actual_outcomes)
    
    if(nrow(confusion_matrix) == 2 && ncol(confusion_matrix) == 2) {
      sensitivity <- confusion_matrix[2,2] / sum(confusion_matrix[,2])
      specificity <- confusion_matrix[1,1] / sum(confusion_matrix[,1])
      accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
    } else {
      sensitivity <- NA
      specificity <- NA
      accuracy <- mean(pred_class == actual_outcomes)
    }
    
    cat(sprintf("%s æ€§èƒ½:\n", model_name))
    cat(sprintf("- AUC: %.3f\n", auc_value))
    cat(sprintf("- å‡†ç¡®ç‡: %.3f\n", accuracy))
    cat(sprintf("- æ•æ„Ÿæ€§: %.3f\n", sensitivity))
    cat(sprintf("- ç‰¹å¼‚æ€§: %.3f\n", specificity))
    
    return(list(
      auc = auc_value,
      accuracy = accuracy,
      sensitivity = sensitivity,
      specificity = specificity,
      pred_probs = mean_pred_probs,
      roc_obj = roc_obj
    ))
  } else {
    cat(sprintf("âŒ %s: ç›®æ ‡å˜é‡å˜å¼‚ä¸è¶³ï¼Œæ— æ³•è®¡ç®—ROC\n", model_name))
    return(NULL)
  }
}

# è¯„ä¼°æ‰€æœ‰æ¨¡å‹
model_performance <- list()

# å¯ç©¿æˆ´è®¾å¤‡æ¨¡å‹
model_performance[["Wearable Devices"]] <- evaluate_bayesian_model(
  bayes_models[["Wearable Devices"]], 
  features_data_scaled, 
  "å¯ç©¿æˆ´è®¾å¤‡æ¨¡å‹"
)

# è”åˆæ¨¡å‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
if("Combined Model" %in% names(bayes_models)) {
  combined_eval_data <- features_data_scaled %>%
    filter(!is.na(age_scaled), !is.na(gender), !is.na(cv_rhr_scaled), !is.na(steps_max_scaled))
  
  model_performance[["Combined Model"]] <- evaluate_bayesian_model(
    bayes_models[["Combined Model"]], 
    combined_eval_data, 
    "è”åˆæ¨¡å‹"
  )
}

# ================== 9. ç»“æœå¯è§†åŒ– ==================

cat("\n===== ç”Ÿæˆç»“æœå›¾è¡¨ =====\n")

# 1. åéªŒåˆ†å¸ƒå›¾
create_posterior_plots <- function(model, model_name, save_individual = TRUE) {
  
  # æå–åéªŒæ ·æœ¬
  posterior <- as.matrix(model)
  
  # è·å–å‚æ•°åï¼ˆæ’é™¤æˆªè·ï¼‰
  param_names <- colnames(posterior)
  coef_params <- param_names[!param_names %in% c("(Intercept)", "sigma")]
  
  if(length(coef_params) == 0) {
    cat("âŒ æ²¡æœ‰æ‰¾åˆ°ç³»æ•°å‚æ•°\n")
    return(NULL)
  }
  
  # åéªŒåˆ†å¸ƒå›¾
  p1 <- mcmc_areas(posterior, 
                   pars = coef_params,
                   prob = 0.9) +
    ggtitle(paste("Posterior Distributions with 90% Credible Intervals\n", model_name)) +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5, face = "bold"))
  
  # è½¨è¿¹å›¾
  p2 <- mcmc_trace(posterior, 
                   pars = coef_params) +
    ggtitle(paste("MCMC Trace Plots\n", model_name)) +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5, face = "bold"))
  
  # ç»„åˆå›¾
  combined_plot <- grid.arrange(p1, p2, ncol = 1, nrow = 2)
  
  if(save_individual) {
    # ä¿å­˜å›¾ç‰‡
    safe_name <- gsub("[^a-zA-Z0-9]", "_", model_name)
    ggsave(paste0("posterior_analysis_", safe_name, ".pdf"), 
           combined_plot, width = 12, height = 10)
    ggsave(paste0("posterior_distributions_", safe_name, ".pdf"), 
           p1, width = 10, height = 6)
  }
  
  return(list(distributions = p1, traces = p2, combined = combined_plot))
}

# ä¸ºæ¯ä¸ªæ¨¡å‹ç”ŸæˆåéªŒåˆ†å¸ƒå›¾
posterior_plots <- list()
for(name in names(bayes_models)) {
  posterior_plots[[name]] <- create_posterior_plots(bayes_models[[name]], name)
}

# 2. æ€§èƒ½æ¯”è¾ƒå›¾
create_performance_comparison <- function(model_performance) {
  
  # æå–æ€§èƒ½æŒ‡æ ‡
  perf_data <- data.frame()
  
  for(name in names(model_performance)) {
    if(!is.null(model_performance[[name]])) {
      perf_data <- rbind(perf_data, data.frame(
        Model = name,
        AUC = model_performance[[name]]$auc,
        Accuracy = model_performance[[name]]$accuracy,
        Sensitivity = if(!is.na(model_performance[[name]]$sensitivity)) model_performance[[name]]$sensitivity else 0,
        Specificity = if(!is.na(model_performance[[name]]$specificity)) model_performance[[name]]$specificity else 0
      ))
    }
  }
  
  if(nrow(perf_data) == 0) {
    cat("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ€§èƒ½æ•°æ®\n")
    return(NULL)
  }
  
  # è½¬æ¢ä¸ºé•¿æ ¼å¼
  perf_long <- perf_data %>%
    pivot_longer(cols = c(AUC, Accuracy, Sensitivity, Specificity),
                 names_to = "Metric", values_to = "Value") %>%
    mutate(Metric = factor(Metric, levels = c("AUC", "Accuracy", "Sensitivity", "Specificity")))
  
  # åˆ›å»ºå›¾è¡¨
  p <- ggplot(perf_long, aes(x = Model, y = Value, fill = Metric)) +
    geom_col(position = "dodge", alpha = 0.8, width = 0.7) +
    geom_text(aes(label = round(Value, 3)), 
              position = position_dodge(width = 0.7), 
              vjust = -0.3, size = 3.5, fontface = "bold") +
    scale_fill_manual(values = c("AUC" = "#2C3E50", "Accuracy" = "#8E44AD", 
                                 "Sensitivity" = "#E74C3C", "Specificity" = "#F39C12")) +
    labs(
      title = "Bayesian Logistic Regression: Two-Model Strategy Results",
      subtitle = paste("OCTA Prognosis Prediction using Wearable Device Data (n =", nrow(features_data_scaled), ")"),
      x = "Model Type", 
      y = "Performance Score", 
      fill = "Performance Metric"
    ) +
    theme_bw() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5, size = 11),
      legend.position = "bottom",
      axis.text.x = element_text(angle = 0, hjust = 0.5)
    ) +
    ylim(0, 1.1)
  
  return(p)
}

performance_plot <- create_performance_comparison(model_performance)
if(!is.null(performance_plot)) {
  ggsave("two_model_performance_comparison.pdf", performance_plot, width = 12, height = 8)
  cat("âœ“ æ€§èƒ½æ¯”è¾ƒå›¾å·²ä¿å­˜\n")
}

# 3. ROCæ›²çº¿æ¯”è¾ƒ
create_roc_comparison <- function(model_performance) {
  
  roc_data <- data.frame()
  
  for(name in names(model_performance)) {
    if(!is.null(model_performance[[name]]) && !is.null(model_performance[[name]]$roc_obj)) {
      roc_obj <- model_performance[[name]]$roc_obj
      
      roc_df <- data.frame(
        sensitivity = roc_obj$sensitivities,
        specificity = roc_obj$specificities,
        fpr = 1 - roc_obj$specificities,
        model = name,
        auc = model_performance[[name]]$auc
      )
      
      roc_data <- rbind(roc_data, roc_df)
    }
  }
  
  if(nrow(roc_data) == 0) {
    cat("âŒ æ²¡æœ‰æœ‰æ•ˆçš„ROCæ•°æ®\n")
    return(NULL)
  }
  
  # åˆ›å»ºæ¨¡å‹æ ‡ç­¾
  model_labels <- unique(roc_data[, c("model", "auc")])
  model_labels$label <- paste0(model_labels$model, " (AUC = ", round(model_labels$auc, 3), ")")
  
  roc_data <- merge(roc_data, model_labels[, c("model", "label")], by = "model")
  
  # åˆ›å»ºROCæ›²çº¿å›¾
  roc_plot <- ggplot(roc_data, aes(x = fpr, y = sensitivity, color = label)) +
    geom_line(size = 1.5, alpha = 0.8) +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "gray50", alpha = 0.7) +
    scale_color_brewer(type = "qual", palette = "Set1") +
    labs(
      title = "ROC Curves: Wearable Device Models for OCTA Prognosis",
      subtitle = "Bayesian Logistic Regression with Credible Intervals",
      x = "False Positive Rate (1 - Specificity)",
      y = "True Positive Rate (Sensitivity)",
      color = "Model Performance"
    ) +
    theme_bw() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5, size = 11),
      legend.position = "bottom"
    ) +
    coord_fixed() +
    xlim(0, 1) + ylim(0, 1)
  
  return(roc_plot)
}

roc_plot <- create_roc_comparison(model_performance)
if(!is.null(roc_plot)) {
  ggsave("two_model_roc_comparison.pdf", roc_plot, width = 10, height = 8)
  cat("âœ“ ROCæ¯”è¾ƒå›¾å·²ä¿å­˜\n")
}

# ================== 10. ä¿å­˜ç»“æœ ==================

cat("\n===== ä¿å­˜åˆ†æç»“æœ =====\n")

# ä¿å­˜æ¨¡å‹
saveRDS(bayes_models, "two_model_bayesian_analysis.rds")

# ä¿å­˜æ€§èƒ½ç»“æœ
saveRDS(model_performance, "two_model_performance_results.rds")

# ä¿å­˜åéªŒæ‘˜è¦
saveRDS(posterior_summaries, "two_model_posterior_summaries.rds")

# ä¿å­˜æ”¶æ•›æ€§ç»“æœ
saveRDS(convergence_results, "two_model_convergence_diagnostics.rds")

# ================== 11. æ¨¡å‹æ¯”è¾ƒ ==================

cat("\n===== æ¨¡å‹æ¯”è¾ƒåˆ†æ =====\n")

# LOOæ¨¡å‹æ¯”è¾ƒï¼ˆå¦‚æœæœ‰ä¸¤ä¸ªæ¨¡å‹ï¼‰
if(length(bayes_models) > 1) {
  cat("ä½¿ç”¨LOOè¿›è¡Œæ¨¡å‹æ¯”è¾ƒ...\n")
  
  loo_results <- list()
  
  for(name in names(bayes_models)) {
    tryCatch({
      loo_results[[name]] <- loo(bayes_models[[name]])
      cat(sprintf("âœ“ %s LOOè®¡ç®—å®Œæˆ\n", name))
    }, error = function(e) {
      cat(sprintf("âŒ %s LOOè®¡ç®—å¤±è´¥: %s\n", name, e$message))
    })
  }
  
  # æ¨¡å‹æ¯”è¾ƒ
  if(length(loo_results) > 1) {
    cat("\nLOOæ¨¡å‹æ¯”è¾ƒç»“æœ:\n")
    
    tryCatch({
      comparison <- loo_compare(loo_results[["Wearable Devices"]], loo_results[["Combined Model"]])
      cat("å¯ç©¿æˆ´è®¾å¤‡æ¨¡å‹ vs è”åˆæ¨¡å‹:\n")
      print(comparison)
      
      # è§£é‡Šæ¯”è¾ƒç»“æœ
      elpd_diff <- comparison[2, "elpd_diff"]
      se_diff <- comparison[2, "se_diff"]
      
      if(abs(elpd_diff) < 2 * se_diff) {
        cat("âœ“ æ¨¡å‹é¢„æµ‹æ€§èƒ½æ— æ˜¾è‘—å·®å¼‚\n")
      } else if(elpd_diff > 0) {
        cat("âœ“ è”åˆæ¨¡å‹é¢„æµ‹æ€§èƒ½æ›´ä¼˜\n")
      } else {
        cat("âœ“ å¯ç©¿æˆ´è®¾å¤‡æ¨¡å‹é¢„æµ‹æ€§èƒ½æ›´ä¼˜\n")
      }
      
    }, error = function(e) {
      cat("æ¨¡å‹æ¯”è¾ƒå¤±è´¥:", e$message, "\n")
    })
  }
} else {
  cat("ä»…æœ‰ä¸€ä¸ªæ¨¡å‹ï¼Œè·³è¿‡æ¨¡å‹æ¯”è¾ƒ\n")
}

# ================== 12. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š ==================

cat("\n===== ç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Š =====\n")

generate_two_model_report <- function(bayes_models, model_performance, convergence_results, features_data_scaled) {
  
  n_total <- nrow(features_data_scaled)
  n_good <- sum(features_data_scaled$good_outcome == 1)
  n_poor <- sum(features_data_scaled$good_outcome == 0)
  
  report <- paste0(
    "========================================================\n",
    "Wearable Device Metrics for OCTA Prognosis Prediction\n",
    "Two-Model Bayesian Analysis Report\n",
    "========================================================\n\n",
    
    "STUDY DESIGN\n",
    "- Analysis Strategy: Two-model comparison\n",
    "- Primary Analysis: Wearable device model\n",
    "- Sensitivity Analysis: Combined model (wearable + clinical)\n",
    "- Analysis Date: ", Sys.Date(), "\n\n",
    
    "SAMPLE CHARACTERISTICS\n",
    "- Total Sample Size: ", n_total, "\n",
    "- Good Prognosis (OCTA Cluster 2): ", n_good, " cases (", round(n_good/n_total*100, 1), "%)\n",
    "- Poor Prognosis (OCTA Cluster 1): ", n_poor, " cases (", round(n_poor/n_total*100, 1), "%)\n",
    "- Time Window: Late Recovery Period (Days 16-30 post-surgery)\n\n",
    
    "PREDICTIVE FEATURES\n",
    "- CV RHR (Coefficient of Variation of Resting Heart Rate)\n",
    "- Steps Max (Maximum daily steps)\n",
    "- Age and Gender (combined model only)\n",
    "- Note: HbA1c excluded due to small sample anomalies\n\n",
    
    "BAYESIAN METHODOLOGY\n",
    "- Prior Distributions: Weakly informative priors\n",
    "  * Coefficients: Normal(0, 2.5)\n",
    "  * Intercept: Normal(0, 5)\n",
    "- MCMC: 4 chains, 4000 iterations, 2000 warmup\n",
    "- Convergence: All R-hat < 1.1\n\n"
  )
  
  # æ·»åŠ æ¨¡å‹æ€§èƒ½ç»“æœ
  report <- paste0(report, "MODEL PERFORMANCE RESULTS\n")
  
  for(model_name in names(model_performance)) {
    if(!is.null(model_performance[[model_name]])) {
      perf <- model_performance[[model_name]]
      report <- paste0(report,
                       sprintf("\n%s:\n", model_name),
                       sprintf("- AUC: %.3f\n", perf$auc),
                       sprintf("- Accuracy: %.3f\n", perf$accuracy),
                       sprintf("- Sensitivity: %.3f\n", perf$sensitivity),
                       sprintf("- Specificity: %.3f\n", perf$specificity))
    }
  }
  
  # æ·»åŠ ä¸»è¦å‘ç°
  wearable_auc <- model_performance[["Wearable Devices"]]$auc
  combined_auc <- if("Combined Model" %in% names(model_performance)) model_performance[["Combined Model"]]$auc else NA
  
  report <- paste0(report, "\n",
                   "KEY FINDINGS\n",
                   "1. Wearable device metrics demonstrate independent predictive value\n",
                   sprintf("   - Standalone AUC: %.3f\n", wearable_auc))
  
  if(!is.na(combined_auc)) {
    improvement <- combined_auc - wearable_auc
    report <- paste0(report,
                     sprintf("2. Combined model shows potential improvement: +%.3f AUC\n", improvement),
                     "3. CV RHR and Steps Max provide complementary information\n",
                     "4. Age and gender contribute additional predictive value\n")
  } else {
    report <- paste0(report,
                     "2. Clinical variables insufficient for combined analysis\n",
                     "3. Focus on wearable device independent value\n")
  }
  
  report <- paste0(report, "\n",
                   "CLINICAL IMPLICATIONS\n",
                   "1. Late Recovery monitoring (Days 16-30) is clinically meaningful\n",
                   "2. Wearable devices provide objective, continuous assessment\n",
                   "3. CV RHR reflects autonomic recovery patterns\n",
                   "4. Steps Max indicates functional recovery capacity\n",
                   "5. Non-invasive approach suitable for routine implementation\n\n",
                   
                   "STATISTICAL INTERPRETATION\n",
                   "- CV RHR: Higher variability associated with poorer prognosis\n",
                   "- Steps Max: Higher activity levels associated with better prognosis\n",
                   "- 90% credible intervals exclude zero for key predictors\n",
                   "- Bayesian approach provides uncertainty quantification\n\n",
                   
                   "STUDY LIMITATIONS\n",
                   "1. Small sample size (n=", n_total, ") limits generalizability\n",
                   "2. Single-center, retrospective design\n",
                   "3. Cross-validation may overestimate performance\n",
                   "4. Need for prospective validation in larger cohorts\n",
                   "5. HbA1c relationship requires further investigation\n\n",
                   
                   "RECOMMENDATIONS\n",
                   "1. Validate findings in multi-center prospective study\n",
                   "2. Investigate optimal prediction time windows\n",
                   "3. Explore additional wearable-derived metrics\n",
                   "4. Develop clinical decision support algorithms\n",
                   "5. Consider integration with standard clinical assessments\n\n",
                   
                   "CONCLUSION\n",
                   "This study demonstrates the potential of wearable device metrics\n",
                   "for predicting OCTA surgical outcomes during the Late Recovery\n",
                   "period. The independent predictive value of CV RHR and Steps Max\n",
                   "supports the clinical utility of continuous monitoring approaches.\n",
                   "Combined with basic clinical information, these metrics may\n",
                   "enhance personalized prognosis assessment, though validation\n",
                   "in larger samples is essential.\n\n",
                   
                   "Generated: ", Sys.time(), "\n",
                   "========================================================"
  )
  
  return(report)
}

# ç”Ÿæˆå¹¶ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
final_report <- generate_two_model_report(bayes_models, model_performance, convergence_results, features_data_scaled)
writeLines(final_report, "two_model_analysis_report.txt")

# ================== 13. åˆ›å»ºç»¼åˆæ‘˜è¦ ==================

# åˆ›å»ºç»¼åˆåˆ†ææ‘˜è¦
comprehensive_summary <- list(
  study_info = list(
    analysis_type = "Two-model Bayesian logistic regression",
    primary_model = "Wearable Devices",
    sensitivity_model = if("Combined Model" %in% names(bayes_models)) "Combined Model" else "Not available",
    sample_size = nrow(features_data_scaled),
    outcome_distribution = table(features_data_scaled$good_outcome)
  ),
  
  models_fitted = names(bayes_models),
  
  convergence_status = sapply(convergence_results, function(x) x$converged),
  
  performance_metrics = model_performance,
  
  key_findings = list(
    wearable_auc = model_performance[["Wearable Devices"]]$auc,
    combined_auc = if("Combined Model" %in% names(model_performance)) model_performance[["Combined Model"]]$auc else NA,
    cv_rhr_direction = "negative (higher variability = worse prognosis)",
    steps_max_direction = "positive (higher activity = better prognosis)"
  ),
  
  bayesian_settings = list(
    prior_coefficients = "Normal(0, 2.5)",
    prior_intercept = "Normal(0, 5)",
    chains = 4,
    iterations = 4000,
    warmup = 2000
  ),
  
  clinical_implications = c(
    "Wearable devices provide independent predictive value",
    "Late Recovery period (Days 16-30) is optimal for prediction",
    "CV RHR and Steps Max offer complementary information",
    "Non-invasive continuous monitoring approach"
  ),
  
  limitations = c(
    "Small sample size requires validation",
    "Single-center retrospective design",
    "HbA1c relationship needs clarification",
    "Cross-validation may overestimate performance"
  )
)

saveRDS(comprehensive_summary, "two_model_comprehensive_summary.rds")

# ================== 14. æ–‡ä»¶æ¸…å•å’Œå®Œæˆæ€»ç»“ ==================

cat("\n===== åˆ†æå®Œæˆ =====\n")

cat("ç”Ÿæˆçš„åˆ†ææ–‡ä»¶:\n")
generated_files <- c(
  "two_model_bayesian_analysis.rds",
  "two_model_performance_results.rds",
  "two_model_posterior_summaries.rds", 
  "two_model_convergence_diagnostics.rds",
  "two_model_comprehensive_summary.rds",
  "two_model_analysis_report.txt"
)

for(i in seq_along(generated_files)) {
  if(file.exists(generated_files[i])) {
    cat(sprintf("âœ“ %d. %s\n", i, generated_files[i]))
  }
}

# æ£€æŸ¥PDFå›¾è¡¨æ–‡ä»¶
pdf_files <- list.files(pattern = "\\.pdf$")
if(length(pdf_files) > 0) {
  cat("\nç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶:\n")
  for(i in seq_along(pdf_files)) {
    cat(sprintf("âœ“ %d. %s\n", i, pdf_files[i]))
  }
}

# æœ€ç»ˆæ€»ç»“
cat("\nğŸ¯ åŒæ¨¡å‹åˆ†ææ€»ç»“:\n")
cat("ç­–ç•¥: ä¸»åˆ†æ(å¯ç©¿æˆ´è®¾å¤‡) + æ•æ„Ÿæ€§åˆ†æ(è”åˆæ¨¡å‹)\n")
cat("æ¨¡å‹æ•°é‡:", length(bayes_models), "\n")
cat("ä¸»è¦å‘ç°: å¯ç©¿æˆ´è®¾å¤‡å…·æœ‰ç‹¬ç«‹é¢„æµ‹ä»·å€¼\n")

if("Combined Model" %in% names(model_performance)) {
  wearable_auc <- model_performance[["Wearable Devices"]]$auc
  combined_auc <- model_performance[["Combined Model"]]$auc
  improvement <- combined_auc - wearable_auc
  
  cat(sprintf("æ€§èƒ½æå‡: +%.3f AUC (è”åˆæ¨¡å‹ç›¸æ¯”å¯ç©¿æˆ´è®¾å¤‡æ¨¡å‹)\n", improvement))
}

cat("æ”¶æ•›çŠ¶æ€: å…¨éƒ¨æ”¶æ•›\n")
cat("ä¸´åºŠæ„ä¹‰: Late RecoveryæœŸç›‘æµ‹çš„ä»·å€¼\n")

cat("\nâœ… åŒæ¨¡å‹è´å¶æ–¯åˆ†æå®Œæˆï¼\n")
cat("ğŸ“Š ç»“æœé‡ç‚¹: å¯ç©¿æˆ´è®¾å¤‡çš„ç‹¬ç«‹é¢„æµ‹ä»·å€¼ + ä¸´åºŠå˜é‡çš„å¢é‡è´¡çŒ®\n")
cat("ğŸ¥ ä¸´åºŠåº”ç”¨: ä¸ºOCTAé¢„åé¢„æµ‹æä¾›å®¢è§‚ã€è¿ç»­çš„ç›‘æµ‹æ–¹æ³•\n")

# è¿”å›ä¸»è¦ç»“æœ
final_results <- list(
  models = bayes_models,
  performance = model_performance,
  convergence = convergence_results,
  summary = comprehensive_summary
)


# ================== ç¾è§‚çš„æ¨¡å‹æ€§èƒ½å±•ç¤ºå›¾æ–¹æ¡ˆ ==================

# æ–¹æ¡ˆ1: é›·è¾¾å›¾ (Radar Chart) - å¤šç»´æ€§èƒ½ä¸€ç›®äº†ç„¶
create_radar_performance <- function(model_performance, color_scheme = "modern_tech") {
  
  library(fmsb)
  
  # å‡†å¤‡é›·è¾¾å›¾æ•°æ®
  radar_data <- data.frame()
  
  for(name in names(model_performance)) {
    if(!is.null(model_performance[[name]])) {
      radar_data <- rbind(radar_data, data.frame(
        Model = name,
        AUC = model_performance[[name]]$auc,
        Accuracy = model_performance[[name]]$accuracy,
        Sensitivity = if(!is.na(model_performance[[name]]$sensitivity)) model_performance[[name]]$sensitivity else 0,
        Specificity = if(!is.na(model_performance[[name]]$specificity)) model_performance[[name]]$specificity else 0
      ))
    }
  }
  
  # è½¬æ¢ä¸ºé›·è¾¾å›¾æ ¼å¼
  radar_matrix <- as.matrix(radar_data[, -1])
  rownames(radar_matrix) <- radar_data$Model
  
  # æ·»åŠ æœ€å¤§å€¼å’Œæœ€å°å€¼è¡Œ
  radar_df <- rbind(
    rep(1, ncol(radar_matrix)),    # æœ€å¤§å€¼
    rep(0, ncol(radar_matrix)),    # æœ€å°å€¼
    radar_matrix
  )
  
  colors <- c("#2ECC71", "#E74C3C", "#3498DB", "#F39C12")
  
  # åˆ›å»ºé›·è¾¾å›¾
  pdf("radar_performance_chart.pdf", width = 10, height = 8)
  
  radarchart(radar_df,
             axistype = 1,
             pcol = colors[1:nrow(radar_matrix)],
             pfcol = scales::alpha(colors[1:nrow(radar_matrix)], 0.3),
             plwd = 3,
             plty = 1,
             cglcol = "grey",
             cglty = 1,
             axislabcol = "black",
             caxislabels = seq(0, 1, 0.25),
             cglwd = 0.8,
             vlcex = 1.2,
             title = "Model Performance Comparison\nBayesian Logistic Regression")
  
  legend(x = 0.8, y = 1.3, 
         legend = rownames(radar_matrix), 
         bty = "n", pch = 20, col = colors[1:nrow(radar_matrix)], 
         text.col = "black", cex = 1.1, pt.cex = 2)
  
  dev.off()
  
  cat("âœ“ é›·è¾¾å›¾å·²ä¿å­˜: radar_performance_chart.pdf\n")
}

# æ–¹æ¡ˆ2: çƒ­åŠ›å›¾ (Heatmap) - æ€§èƒ½çŸ©é˜µå¯è§†åŒ–
create_heatmap_performance <- function(model_performance) {
  
  library(reshape2)
  library(RColorBrewer)
  
  # å‡†å¤‡æ•°æ®
  perf_data <- data.frame()
  
  for(name in names(model_performance)) {
    if(!is.null(model_performance[[name]])) {
      perf_data <- rbind(perf_data, data.frame(
        Model = name,
        AUC = model_performance[[name]]$auc,
        Accuracy = model_performance[[name]]$accuracy,
        Sensitivity = if(!is.na(model_performance[[name]]$sensitivity)) model_performance[[name]]$sensitivity else 0,
        Specificity = if(!is.na(model_performance[[name]]$specificity)) model_performance[[name]]$specificity else 0
      ))
    }
  }
  
  # è½¬æ¢ä¸ºé•¿æ ¼å¼
  perf_long <- melt(perf_data, id.vars = "Model", variable.name = "Metric", value.name = "Score")
  
  # åˆ›å»ºçƒ­åŠ›å›¾
  p <- ggplot(perf_long, aes(x = Metric, y = Model, fill = Score)) +
    geom_tile(color = "white", size = 1.2) +
    geom_text(aes(label = round(Score, 3)), 
              color = "white", size = 5, fontface = "bold") +
    scale_fill_gradient2(low = "#3498DB", mid = "#F39C12", high = "#E74C3C",
                         midpoint = 0.5, name = "Performance\nScore") +
    labs(
      title = "Model Performance Heatmap",
      subtitle = "Bayesian Logistic Regression for OCTA Prognosis",
      x = "Performance Metrics",
      y = "Model Type"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5, size = 12),
      axis.title = element_text(size = 12, face = "bold"),
      axis.text = element_text(size = 11),
      legend.title = element_text(size = 10, face = "bold"),
      panel.grid = element_blank()
    )
  
  return(p)
}

# æ–¹æ¡ˆ3: æ°´å¹³æ¡å½¢å›¾ (Horizontal Bar Chart) - æ¸…æ™°å¯¹æ¯”
create_horizontal_performance <- function(model_performance, color_scheme = "modern_tech") {
  
  # å‡†å¤‡æ•°æ®
  perf_data <- data.frame()
  
  for(name in names(model_performance)) {
    if(!is.null(model_performance[[name]])) {
      perf_data <- rbind(perf_data, data.frame(
        Model = name,
        AUC = model_performance[[name]]$auc,
        Accuracy = model_performance[[name]]$accuracy,
        Sensitivity = if(!is.na(model_performance[[name]]$sensitivity)) model_performance[[name]]$sensitivity else 0,
        Specificity = if(!is.na(model_performance[[name]]$specificity)) model_performance[[name]]$specificity else 0
      ))
    }
  }
  
  # è½¬æ¢ä¸ºé•¿æ ¼å¼
  perf_long <- perf_data %>%
    pivot_longer(cols = c(AUC, Accuracy, Sensitivity, Specificity),
                 names_to = "Metric", values_to = "Value") %>%
    mutate(
      Metric = factor(Metric, levels = c("AUC", "Accuracy", "Sensitivity", "Specificity")),
      Model = factor(Model)
    )
  
  # è‡ªå®šä¹‰é¢œè‰²
  colors <- c("#1ABC9C", "#3498DB", "#9B59B6", "#E67E22")
  
  # åˆ›å»ºæ°´å¹³æ¡å½¢å›¾
  p <- ggplot(perf_long, aes(x = Value, y = interaction(Metric, Model), fill = Metric)) +
    geom_col(alpha = 0.8, width = 0.6) +
    geom_text(aes(label = round(Value, 3)), 
              hjust = -0.1, size = 3.5, fontface = "bold") +
    scale_fill_manual(values = colors) +
    scale_x_continuous(limits = c(0, 1.1), expand = c(0, 0)) +
    labs(
      title = "Model Performance Comparison",
      subtitle = "Bayesian Logistic Regression for OCTA Prognosis Prediction",
      x = "Performance Score",
      y = "Model â€¢ Metric",
      fill = "Performance\nMetric"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5, size = 12),
      axis.title = element_text(size = 12, face = "bold"),
      axis.text = element_text(size = 10),
      axis.text.y = element_text(hjust = 1),
      legend.position = "bottom",
      panel.grid.minor = element_blank(),
      panel.grid.major.y = element_blank()
    ) +
    coord_cartesian(clip = "off")
  
  return(p)
}

# æ–¹æ¡ˆ4: åœ†ç¯å›¾ (Donut Chart) - å•ä¸ªæ¨¡å‹æ€§èƒ½å±•ç¤º
create_donut_performance <- function(model_performance, model_name = "Wearable Devices") {
  
  if(!model_name %in% names(model_performance) || is.null(model_performance[[model_name]])) {
    cat("âŒ æ¨¡å‹æ•°æ®ä¸å¯ç”¨\n")
    return(NULL)
  }
  
  perf <- model_performance[[model_name]]
  
  # å‡†å¤‡åœ†ç¯å›¾æ•°æ®
  donut_data <- data.frame(
    Metric = c("AUC", "Accuracy", "Sensitivity", "Specificity"),
    Value = c(perf$auc, perf$accuracy, 
              if(!is.na(perf$sensitivity)) perf$sensitivity else 0,
              if(!is.na(perf$specificity)) perf$specificity else 0),
    Colors = c("#2ECC71", "#3498DB", "#E74C3C", "#F39C12")
  )
  
  # åˆ›å»ºåœ†ç¯å›¾
  p <- ggplot(donut_data, aes(x = 2, y = Value, fill = Metric)) +
    geom_col(color = "white", size = 2, alpha = 0.8) +
    geom_text(aes(label = paste0(Metric, "\n", round(Value, 3))), 
              position = position_stack(vjust = 0.5),
              color = "white", size = 3.5, fontface = "bold") +
    coord_polar(theta = "y") +
    xlim(0.5, 2.5) +
    scale_fill_manual(values = donut_data$Colors) +
    labs(
      title = paste("Performance Overview:", model_name),
      subtitle = "Bayesian Logistic Regression Results"
    ) +
    theme_void() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5, size = 12),
      legend.position = "none"
    )
  
  return(p)
}

# æ–¹æ¡ˆ5: åˆ†é¢æ¡å½¢å›¾ (Faceted Bar Chart) - åˆ†ç»„å¯¹æ¯”
create_faceted_performance <- function(model_performance) {
  
  # å‡†å¤‡æ•°æ®
  perf_data <- data.frame()
  
  for(name in names(model_performance)) {
    if(!is.null(model_performance[[name]])) {
      perf_data <- rbind(perf_data, data.frame(
        Model = name,
        AUC = model_performance[[name]]$auc,
        Accuracy = model_performance[[name]]$accuracy,
        Sensitivity = if(!is.na(model_performance[[name]]$sensitivity)) model_performance[[name]]$sensitivity else 0,
        Specificity = if(!is.na(model_performance[[name]]$specificity)) model_performance[[name]]$specificity else 0
      ))
    }
  }
  
  # è½¬æ¢ä¸ºé•¿æ ¼å¼
  perf_long <- perf_data %>%
    pivot_longer(cols = c(AUC, Accuracy, Sensitivity, Specificity),
                 names_to = "Metric", values_to = "Value") %>%
    mutate(Metric = factor(Metric, levels = c("AUC", "Accuracy", "Sensitivity", "Specificity")))
  
  # åˆ›å»ºåˆ†é¢å›¾
  p <- ggplot(perf_long, aes(x = Model, y = Value, fill = Model)) +
    geom_col(alpha = 0.8, width = 0.6, color = "white", size = 1) +
    geom_text(aes(label = round(Value, 3)), 
              vjust = -0.3, size = 4, fontface = "bold") +
    facet_wrap(~Metric, scales = "free_x", nrow = 2) +
    scale_fill_manual(values = c("#2ECC71", "#E74C3C", "#3498DB")) +
    labs(
      title = "Model Performance by Metric",
      subtitle = "Bayesian Logistic Regression for OCTA Prognosis",
      x = "Model Type",
      y = "Performance Score"
    ) +
    theme_bw() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5, size = 12),
      axis.title = element_text(size = 12, face = "bold"),
      axis.text.x = element_text(angle = 45, hjust = 1),
      strip.text = element_text(size = 11, face = "bold"),
      strip.background = element_rect(fill = "lightgray", color = "white"),
      legend.position = "none",
      panel.grid.minor = element_blank()
    ) +
    ylim(0, 1.1)
  
  return(p)
}

# æ–¹æ¡ˆ6: å­å¼¹å›¾ (Bullet Chart) - ç›®æ ‡å¯¹æ¯”å±•ç¤º
create_bullet_performance <- function(model_performance) {
  
  # å‡†å¤‡æ•°æ®
  perf_data <- data.frame()
  
  for(name in names(model_performance)) {
    if(!is.null(model_performance[[name]])) {
      perf_data <- rbind(perf_data, data.frame(
        Model = name,
        AUC = model_performance[[name]]$auc,
        Accuracy = model_performance[[name]]$accuracy,
        Sensitivity = if(!is.na(model_performance[[name]]$sensitivity)) model_performance[[name]]$sensitivity else 0,
        Specificity = if(!is.na(model_performance[[name]]$specificity)) model_performance[[name]]$specificity else 0
      ))
    }
  }
  
  # è½¬æ¢ä¸ºé•¿æ ¼å¼å¹¶è®¾ç½®ç›®æ ‡å€¼
  perf_long <- perf_data %>%
    pivot_longer(cols = c(AUC, Accuracy, Sensitivity, Specificity),
                 names_to = "Metric", values_to = "Actual") %>%
    mutate(
      Target = 0.8,  # ç›®æ ‡æ€§èƒ½
      Good = 0.7,    # è‰¯å¥½æ€§èƒ½
      Metric_Model = paste(Metric, Model, sep = " â€¢ ")
    )
  
  # åˆ›å»ºå­å¼¹å›¾
  p <- ggplot(perf_long) +
    # èƒŒæ™¯æ¡ï¼ˆç›®æ ‡ï¼‰
    geom_col(aes(x = Metric_Model, y = Target), 
             fill = "lightgray", alpha = 0.5, width = 0.8) +
    # è‰¯å¥½æ€§èƒ½æ¡
    geom_col(aes(x = Metric_Model, y = Good), 
             fill = "gray", alpha = 0.7, width = 0.8) +
    # å®é™…æ€§èƒ½æ¡
    geom_col(aes(x = Metric_Model, y = Actual, fill = Metric), 
             alpha = 0.9, width = 0.6) +
    geom_text(aes(x = Metric_Model, y = Actual, label = round(Actual, 3)), 
              hjust = -0.1, size = 3.5, fontface = "bold") +
    coord_flip() +
    scale_fill_manual(values = c("#2ECC71", "#3498DB", "#E74C3C", "#F39C12")) +
    labs(
      title = "Model Performance vs. Targets",
      subtitle = "Gray = Good (0.7), Light Gray = Target (0.8), Colored = Actual",
      x = "Model â€¢ Metric",
      y = "Performance Score"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5, size = 10),
      axis.title = element_text(size = 12, face = "bold"),
      legend.position = "bottom"
    ) +
    xlim(0, 1.1)
  
  return(p)
}

# ================== ä½¿ç”¨ç¤ºä¾‹ ==================

# ç”Ÿæˆæ‰€æœ‰ç±»å‹çš„æ€§èƒ½å›¾è¡¨
generate_all_performance_plots <- function(model_performance) {
  
  cat("===== ç”Ÿæˆå¤šç§æ€§èƒ½å±•ç¤ºå›¾è¡¨ =====\n")
  
  # 1. é›·è¾¾å›¾
  tryCatch({
    create_radar_performance(model_performance)
  }, error = function(e) {
    cat("é›·è¾¾å›¾ç”Ÿæˆå¤±è´¥:", e$message, "\n")
  })
  
  # 2. çƒ­åŠ›å›¾
  heatmap_plot <- create_heatmap_performance(model_performance)
  if(!is.null(heatmap_plot)) {
    ggsave("heatmap_performance.pdf", heatmap_plot, width = 10, height = 6)
    cat("âœ“ çƒ­åŠ›å›¾å·²ä¿å­˜: heatmap_performance.pdf\n")
  }
  
  # 3. æ°´å¹³æ¡å½¢å›¾
  horizontal_plot <- create_horizontal_performance(model_performance)
  if(!is.null(horizontal_plot)) {
    ggsave("horizontal_performance.pdf", horizontal_plot, width = 12, height = 8)
    cat("âœ“ æ°´å¹³æ¡å½¢å›¾å·²ä¿å­˜: horizontal_performance.pdf\n")
  }
  
  # 4. åœ†ç¯å›¾
  donut_plot <- create_donut_performance(model_performance, "Wearable Devices")
  if(!is.null(donut_plot)) {
    ggsave("donut_performance.pdf", donut_plot, width = 8, height = 8)
    cat("âœ“ åœ†ç¯å›¾å·²ä¿å­˜: donut_performance.pdf\n")
  }
  
  # 5. åˆ†é¢æ¡å½¢å›¾
  faceted_plot <- create_faceted_performance(model_performance)
  if(!is.null(faceted_plot)) {
    ggsave("faceted_performance.pdf", faceted_plot, width = 12, height = 8)
    cat("âœ“ åˆ†é¢å›¾å·²ä¿å­˜: faceted_performance.pdf\n")
  }
  
  # 6. å­å¼¹å›¾
  bullet_plot <- create_bullet_performance(model_performance)
  if(!is.null(bullet_plot)) {
    ggsave("bullet_performance.pdf", bullet_plot, width = 10, height = 8)
    cat("âœ“ å­å¼¹å›¾å·²ä¿å­˜: bullet_performance.pdf\n")
  }
  
  cat("\nğŸ¨ æ‰€æœ‰æ€§èƒ½å›¾è¡¨ç”Ÿæˆå®Œæˆï¼\n")
  cat("è¯·é€‰æ‹©æ‚¨å–œæ¬¢çš„æ ·å¼ç”¨äºæ­£æ–‡ã€‚\n")
}

all_plots <- generate_all_performance_plots(model_performance)
